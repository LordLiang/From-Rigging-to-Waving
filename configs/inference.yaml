# manual setting
max_frames: 32
resolution: [512, 768]  # or resolution: [768, 1216]
resize: True
round: 1 
ddim_timesteps: 20  # among 25-50
seed: 11 
latent_coarse_image: False
mask_dilation: False
kernel_size: 5
tau_alpha: 0.8 # 0.0 for w/o SDI
tau_beta: 0.6 # 0.0 for w/o SDI
test_list_path:  [
    [2, 'data/rigging2waving_dataset_test/no_mask/ebc18447b94841d1a4af655ca7042d86/char/texture.png',
    'data/rigging2waving_dataset_test/no_mask/ebc18447b94841d1a4af655ca7042d86/blender_render/animation1/openpose'],
]


partial_keys: [
                    ['image', 'randomref', 'coarse_image', 'dwpose'],
                    #['image', 'local_image', "dwpose"],
                ]


# default settings
TASK_TYPE: inference_rigging2waving_entrance
guide_scale: 2.5
vit_resolution: [224, 224]
use_fp16: True
batch_size: 1
latent_random_ref: True
chunk_size: 2
decoder_bs: 2
scale: 8
use_fps_condition: False
pretrained_model: checkpoints/unianimate_16f_32f_non_ema_223000.pth
tuned_model: checkpoints-latest/sp-non_ema_00040000-latest.pth

embedder: {
    'type': 'FrozenOpenCLIPTextVisualEmbedder',
    'layer': 'penultimate',
    'pretrained': 'checkpoints/open_clip_pytorch_model.bin'
}


auto_encoder: {
    'type': 'AutoencoderKL',
    'ddconfig': {
        'double_z': True, 
        'z_channels': 4,
        'resolution': 256, 
        'in_channels': 3,
        'out_ch': 3, 
        'ch': 128, 
        'ch_mult': [1, 2, 4, 4],
        'num_res_blocks': 2, 
        'attn_resolutions': [], 
        'dropout': 0.0,
        'video_kernel_size': [3, 1, 1]
    },
    'embed_dim': 4,
    'pretrained': 'checkpoints/v2-1_512-ema-pruned.ckpt'
}



UNet_pre: {
    'type': 'UNetSD_UniAnimate',
    'config': None,
    'in_dim': 4,
    'dim': 320,
    'y_dim': 1024,
    'context_dim': 1024,
    'out_dim': 4,
    'dim_mult': [1, 2, 4, 4],
    'attn_scales': [1.0,0.5,0.25],
    'num_heads': 8,
    'head_dim': 64,
    'num_res_blocks': 2,
    'dropout': 0.1,
    'temporal_attention': True,
    'num_tokens': 4,
    'temporal_attn_times': 1,
    'use_checkpoint': True,
    'use_fps_condition': False,
    'use_sim_mask': False
}
video_compositions: ['image', 'local_image', 'dwpose', 'randomref', 'randomref_pose'] #for original unianimate

UNet_tune: {
    'type': 'UNetSD_Rigging2Waving',
    'config': None,
    'in_dim': 4,
    'dim': 320,
    'y_dim': 1024,
    'context_dim': 1024,
    'out_dim': 4,
    'dim_mult': [1, 2, 4, 4],
    'attn_scales': [1.0,0.5,0.25],
    'num_heads': 8,
    'head_dim': 64,
    'num_res_blocks': 2,
    'dropout': 0.1,
    'temporal_attention': True,
    'num_tokens': 4,
    'temporal_attn_times': 1,
    'use_checkpoint': True,
    'use_fps_condition': False,
    'use_sim_mask': False
}


Diffusion: {
    'type': 'DiffusionDDIM',
    'schedule': 'linear_sd', 
    'schedule_param': {
        'num_timesteps': 1000,
        "init_beta": 0.00085, 
        "last_beta": 0.0120,
        'zero_terminal_snr': True,
    },
    'mean_type': 'v',
    'loss_type': 'mse',
    'var_type': 'fixed_small', # 'fixed_large',
    'rescale_timesteps': False,
    'noise_strength': 0.1
}
use_DiffusionDPM: False
CPU_CLIP_VAE: True
add_noise_prior: True
noise_prior_value: 949 # or 999, 949

#random_ratio: 0.0


